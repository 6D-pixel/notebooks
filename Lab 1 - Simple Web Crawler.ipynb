{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2p9GNA9OGMcX"
   },
   "source": [
    "# **Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ybW_FxsdF6Bs"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UXrAYrruF7JI"
   },
   "outputs": [],
   "source": [
    "root_URL = \"http://www.vit.ac.in\"\n",
    "search_word = \"research\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXpWbJNpF8tO",
    "outputId": "3a382993-2ad4-4560-945c-f542e94dc1b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of the response :  200\n"
     ]
    }
   ],
   "source": [
    "# Use the requests library to retrieve the web page of the root URL\n",
    "\n",
    "response = requests.get(root_URL)\n",
    "print(\"Status of the response : \", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "f7w4osRTF-qG"
   },
   "outputs": [],
   "source": [
    "# Use the Beautiful Soap library to parse the retrieved web page\n",
    "\n",
    "root_page = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "URx99FtzGAGC"
   },
   "outputs": [],
   "source": [
    "# Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
    "\n",
    "anchor_tags = root_page.find_all('a')\n",
    "\n",
    "result = []\n",
    "\n",
    "# Check if the word \"research\" is present in each page, and if so then save its URL\n",
    "for anchor_tag in anchor_tags :\n",
    "    link = anchor_tag['href']\n",
    "    if re.search(search_word, link, re.IGNORECASE) :\n",
    "        result.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RyBeByMfGBga",
    "outputId": "bdd2504c-1407-43f8-9761-888e21905fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The links in the root URL page which contains the word 'research' are below: \n",
      "\t https://vit.ac.in/admissions/research\n",
      "\t https://vit.ac.in/admissions/research/Integrated_Ph.D\n",
      "\t https://vit.ac.in/admissions/research/phd\n",
      "\t https://vit.ac.in/research\n",
      "\t https://vit.ac.in/research\n",
      "\t https://vit.ac.in/research/academic\n",
      "\t https://vit.ac.in/research/sponsored-research\n",
      "\t https://vit.ac.in/research/centers-list\n",
      "\t 3d-printing-play-major-role-mitigating-spread-covid-19-say-researchers-vit\n",
      "\t 3d-printing-play-major-role-mitigating-spread-covid-19-say-researchers-vit\n",
      "\t https://vit.ac.in/research\n"
     ]
    }
   ],
   "source": [
    "print(\"The links in the root URL page which contains the word 'research' are below: \")\n",
    "for url in result[0:25] :\n",
    "    print(\"\\t\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52c8URSkGmS2"
   },
   "source": [
    "## **Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lARg43xYGqHO"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zFVQtIGaG1m4",
    "outputId": "2b4aeced-970f-49c0-c0a8-d8bd5e9582dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of the response :  200\n"
     ]
    }
   ],
   "source": [
    "# Use the requests library to retrieve the web page of the root URL\n",
    "response = requests.get(\"https://vit.ac.in/\")\n",
    "print(\"Status of the response : \", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZYh6Zw2cG9yd"
   },
   "outputs": [],
   "source": [
    "# Use the Beautiful Soap library to parse the retrieved web page\n",
    "root_page = BeautifulSoup(response.content, 'html.parser')\n",
    "# Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
    "anchor_tags = root_page.find_all('a')\n",
    "result = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IC7z4_tfHB3d",
    "outputId": "019a6475-398d-4b41-91c0-70693acb96e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The links in the root URL page which contains the word 'admissions' and 'international are :\n",
      "\t https://vit.ac.in/admissions/international\n",
      "\t https://vit.ac.in/admissions/international/overview\n"
     ]
    }
   ],
   "source": [
    "# Check if the words \"admissions\" and \"international\"  is present in each page, and if so then save its URL\n",
    "for anchor_tag in anchor_tags :\n",
    "    link = anchor_tag['href']\n",
    "    if re.search(\"admissions\", link, re.IGNORECASE) and re.search(\"international\", link, re.IGNORECASE):\n",
    "        result.append(link)\n",
    "\n",
    "print(\"The links in the root URL page which contains the word 'admissions' and 'international are :\")\n",
    "for url in result :\n",
    "    print(\"\\t\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kf5sQByBHTcP"
   },
   "source": [
    "# **Question 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "AHtvBAr_HXKQ"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vs_MbVqBHZNl",
    "outputId": "b30e69ca-0fc8-46e7-9eef-04dd2fff1e95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status of the response :  200\n"
     ]
    }
   ],
   "source": [
    "# Use the requests library to retrieve the web page of the root URL\n",
    "response = requests.get(\"https://vit.ac.in/\")\n",
    "print(\"Status of the response : \", response.status_code)\n",
    "\n",
    "# Use the Beautiful Soap library to parse the retrieved web page\n",
    "root_page = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4v0H-u8tHd05"
   },
   "outputs": [],
   "source": [
    "# Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
    "\n",
    "anchor_tags = root_page.find_all('a')\n",
    "\n",
    "result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t93WaIzmHgAZ",
    "outputId": "2202765e-09ec-48db-b5f4-de154a30171e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The links in the root URL page which contains the word 'programme' but not the word 'programming' are :\n",
      "\t https://vit.ac.in/programmes-offered-1\n",
      "\t https://vit.ac.in/programmes-offered-2021-22\n",
      "\t https://vit.ac.in/programmes-offered-2020-21\n",
      "\t https://vit.ac.in/admissions/programmes-offered\n"
     ]
    }
   ],
   "source": [
    "# Check if the word \"programme\" is present and not the word \"programming\" in each page, and if so then save its URL\n",
    "for anchor_tag in anchor_tags :\n",
    "    link = anchor_tag['href']\n",
    "    if re.search(\"programme\", link, re.IGNORECASE) and not re.search(\"programming\", link, re.IGNORECASE):\n",
    "        result.append(link)\n",
    "\n",
    "print(\"The links in the root URL page which contains the word 'programme' but not the word 'programming' are :\")\n",
    "for url in result :\n",
    "    print(\"\\t\", url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9JqGqjBIZmd"
   },
   "source": [
    "## **Question 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7AFeACSkL1FL",
    "outputId": "fec84a19-5040-4a61-aa95-8585d2cb98af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your root url: http://www.vit.ac.in/\n",
      "Enter your search word: hostel\n",
      "Number of pages to be searched: 18\n",
      "Status of the response :  200\n",
      "The links in the root URL page which contains the given word are :\n",
      "\t https://vit.ac.in/campuslife/hostels\n",
      "\t https://vit.ac.in/campus-hostel/hostels\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "root_URL = input(\"Please enter your root url: \")\n",
    "search_word1 = input(\"Enter your search word: \")\n",
    "N = int (input(\"Number of pages to be searched: \"))\n",
    "\n",
    "# Use the requests library to retrieve the web page of the root URL\n",
    "\n",
    "response = requests.get(root_URL)\n",
    "print(\"Status of the response : \", response.status_code)\n",
    "\n",
    "# Use the Beautiful Soap library to parse the retrieved web page\n",
    "\n",
    "root_page = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Retrieve all the links to the sub-pages by retrieving all the `<a>` tags\n",
    "\n",
    "anchor_tags = root_page.find_all('a')\n",
    "\n",
    "result = []\n",
    "\n",
    "# Check if the given word  is present in each page, and if so then save its URL\n",
    "for anchor_tag in anchor_tags :\n",
    "    link = anchor_tag['href']\n",
    "    if re.search(search_word1 , link, re.IGNORECASE) :\n",
    "        result.append(link)\n",
    "print(\"The links in the root URL page which contains the given word are :\")\n",
    "for url in result[0:N] :\n",
    "    print(\"\\t\", url)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "19BCE1072_Lab 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
